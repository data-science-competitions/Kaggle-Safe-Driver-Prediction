---
title: "1st Place Solution"
subtitle: "Reconstructing Winning Kaggle Solutions"
subject: "Porto Seguroâ€™s Safe Driver Prediction"
author: "Harel Lustiger"
date: "Dec 2017"
output: html_notebook
---

```{r new_session, echo=FALSE, message=FALSE, warning=FALSE}
rm(list = ls()); cat("\014")
```

# Load Packages

```{r load_libraries, echo=TRUE, message=FALSE, warning=FALSE}
library("tidyverse")
library("recipes")
library("caret")
```


# Import Data

In this dataset, each variable name contains designations about its type and 
group. Thus, the strategy is:

1. Get the data with `R` best guess
2. Extract the variable metadata held in the columns' names 
(as prefix/postfix/suffix) and use it for semi-automatic type-conversion. 

## Get the Data

```{r import_data, echo=TRUE, message=FALSE, warning=FALSE}
PATHS = list()
PATHS[["train"]] = file.path(dirname(getwd()),"data","train.zip")
PATHS[["test"]]= file.path(dirname(getwd()),"data","test.zip")
  
DATASETS = list()
DATASETS[["train"]] = read_csv(PATHS[["train"]], na=c("","NA",-1), n_max=1e2)
DATASETS[["test"]] = read_csv(PATHS[["test"]], na=c("","NA",-1), n_max=1e2)
  
tidy_data = bind_rows(list(train=DATASETS[["train"]], test=DATASETS[["test"]]),
                      .id="set")
```

## Parse the Data

```{r extracting_variables_groups_and_types, message=FALSE, warning=FALSE}
# 1. Extract variables types from their names
col_metadata = data.frame(name=colnames(tidy_data), stringsAsFactors=FALSE)
col_metadata %<>%
    # 1.1 Drop the 'set' row
    filter(name!="set") %>%
    # 1.1 Create new columns to hold the variables' metadata
    separate("name", into=c("prefix","group","number","type"), remove=F) %>%
    # 1.2 The metadata has irrelevant information which we discard
    select(-prefix, -number) %>%
    # By default the dataset creator omitted numeric variables designation. 
    # As a result, numeric variables are assigned with NAs.
    # 1.3 Replace NAs under the type col with "num".
    replace_na(list(type="num"))
  
# 2. Map the original type names with r known types
col_metadata[["type"]] = 
    sapply(col_metadata[["type"]], recode, 
           num="as.numeric", cat="as.factor", bin="as.logical")
  
# 3. Define the target variable to be binary
col_metadata[2,"type"] = "as.logical"
  
# 4. Set the data set variables types
for(j in 1:nrow(col_metadata)){
    col_name = col_metadata[j,"name"]
    col_type = col_metadata[j,"type"]
    # Match between the metadata and data set col numbers
    m = which(colnames(tidy_data) %in% col_name)
    # If the metadata doesn't fit any of the provided data set cols then skip it
    if(!m) next
    # Set the col data type
    tidy_data = tidy_data %>% mutate_at(m, col_type)
}
```


# Data Preprocessing

```{r feature_engineering, message=FALSE, warning=FALSE}
options(na.action='na.pass')
  
# 1. Drop the *calc variables group
tidy_data = tidy_data %>% select(-matches('.+_calc_.+$'))
  
# 2. Data Transformations
# 2.1 An Initial Recipe: declare the variables and their roles 
rec_obj <- recipe(target ~ ., data=tidy_data)
rec_obj = rec_obj %>%
    add_role(id, new_role="id variable") %>%
    add_role(set, new_role="splitting variable")
# 2.2 Preprocessing Steps
rec_obj = rec_obj %>% 
    # 2.2.1 Individual transformations for skewness and other issues
    # 2.2.1.1 Yeo-Johnson Transformation
    step_YeoJohnson(all_numeric(), -id, na.rm=TRUE) %>% 
    # 2.2.1.2 Centering and Scaling Numeric Data
    step_center(all_numeric(), -id) %>%
    step_scale(all_numeric(), -id) %>%
    # 2.2.2 Creating Dummy Variables
    step_dummy(all_nominal(), -set)
# 2.3 Estimate the recipe statistics
rec_obj = rec_obj %>% prep(training=tidy_data)
# 2.4 Apply the recipe to the data set
tidy_data = bake(rec_obj, newdata=tidy_data)
  
options(na.action='na.omit')
#summary(rec_obj)
``` 






